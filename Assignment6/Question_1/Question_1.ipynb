{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmYylv44LQDZ"
   },
   "source": [
    "#### **Welcome to Assignment 6 - Question 1 on Deep Learning for Computer Vision.**\n",
    "\n",
    "This notebook contains code for training generative adversarial network (GAN) model \n",
    "\n",
    "#### **Instructions**\n",
    "1. Use Python 3.x to run this notebook\n",
    "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'. Necessary comments are provided within the lines to help you in the implementation, you should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
    "3. At some places you will only be asked to fill the appropriate values, those places will be marked as '?' \n",
    "4. Read documentation of each function carefully and whenever possible use pytorch functions\n",
    "5. All the Best!\n",
    "6. Total Marks: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TsiJ2P-LQDg"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set for testing purposes, please do not change!\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in a uniform grid.\n",
    "    '''\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqnQWFagLQDh"
   },
   "source": [
    "## Generator Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKjKQ8oCLQDh"
   },
   "source": [
    "### This function creates a single block for generator network. This block contains \n",
    "1. Linear transformation to map to another shape, \n",
    "2. Batch Normalization\n",
    "3. Activation Function (Relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_QWBKsRLQDh"
   },
   "outputs": [],
   "source": [
    "# 1 Mark to fill places marked with '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHjYjEUBLQDi"
   },
   "outputs": [],
   "source": [
    "def get_generator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Function for returning a block of the generator's neural network\n",
    "    given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a generator neural network layer, with a linear transformation \n",
    "          followed by a batch normalization and then a relu activation\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        \n",
    "        #### START CODE HERE ####\n",
    "        # Fill the '?' places with appropriate dimensions\n",
    "        nn.Linear(?, ?),\n",
    "        nn.BatchNorm1d(?),\n",
    "        nn.ReLU(inplace=True),\n",
    "        #### END CODE HERE ####\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0dcvdBRLQDi"
   },
   "outputs": [],
   "source": [
    "# 1-Mark to complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyAzFei9LQDi"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "          (MNIST images are 28 x 28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            \n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
    "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            \n",
    "            #### START CODE HERE ####\n",
    "            # Final Layer containing Linear transformation with in_features from previous layer and out_features as im_dim\n",
    "        \n",
    "            # Sigmoid Activation Function\n",
    "            \n",
    "            #### END CODE HERE ####\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return self.gen(noise)\n",
    "    \n",
    "    # Needed for grading\n",
    "    def get_gen(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            the sequential model\n",
    "        '''\n",
    "        return self.gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se6O1_d5LQDj"
   },
   "source": [
    "### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELfx40znLQDj"
   },
   "outputs": [],
   "source": [
    "# To use generator, we need to create noise vectors. Generate noise vector by sampling random numbers from the normal distribution\n",
    "\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    \n",
    "    # Return noise by sampling random numbers from normal distribution\n",
    "    return torch.randn(n_samples,z_dim,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xva_NbIBLQDj"
   },
   "source": [
    "### Discriminator Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrjZztYnLQDk"
   },
   "outputs": [],
   "source": [
    "# 2-Mark to complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxf4MmauLQDk"
   },
   "outputs": [],
   "source": [
    "def get_discriminator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Discriminator Block\n",
    "    Function for returning a neural network of the discriminator given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a discriminator neural network layer, with \n",
    "            1. a linear transformation, \n",
    "            2. followed by an nn.LeakyReLU activation with negative slope of 0.2 (set inplace as True)\n",
    "          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        #### START CODE HERE ####\n",
    "        \n",
    "        #### END CODE HERE ####\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWzf84DhLQDk"
   },
   "outputs": [],
   "source": [
    "# 2-Mark to complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PX1SjSQfLQDk"
   },
   "outputs": [],
   "source": [
    "# Discriminator Network will build network with 4 layers. Start with the image tensor and perform the transformation until it returns a single number (i.e. 1-dimensional tensor output)\n",
    "# Each intermediate layer in the network will have hidden_dim \n",
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator Class\n",
    "    Values:\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "            (MNIST images are 28x28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, im_dim=784, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            \n",
    "            get_discriminator_block(im_dim, hidden_dim * 4),\n",
    "            \n",
    "            # Layer-2 \n",
    "            get_discriminator_block(hidden_dim * 4,hidden_dim*2),\n",
    "            \n",
    "            #### START CODE HERE ####\n",
    "            \n",
    "            # Layer-3\n",
    "            get_discriminator_block(?, ?),\n",
    "            \n",
    "            \n",
    "            # Layer-4 has only linear transformation with in_features: hidden_dim and out_features: 1\n",
    "            \n",
    "            #### END CODE HERE ####\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        '''\n",
    "        Function for completing a forward pass of the discriminator: Given an image tensor, \n",
    "        returns a 1-dimension tensor representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor with dimension (im_dim)\n",
    "        '''\n",
    "        return self.disc(image)\n",
    "    \n",
    "    # Needed for grading\n",
    "    def get_disc(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            the sequential model\n",
    "        '''\n",
    "        return self.disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NcsCvJWLQDl"
   },
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "\n",
    "# Check availability of GPU and set the device accordingly\n",
    "device = 'cuda'\n",
    "\n",
    "# The following block is to mitigate the temporary issue within PyTorch about downloading MNIST. Don't change!\n",
    "new_mirror = 'https://ossci-datasets.s3.amazonaws.com/mnist'\n",
    "MNIST.resources = [\n",
    "   ('/'.join([new_mirror, url.split('/')[-1]]), md5)\n",
    "   for url, md5 in MNIST.resources\n",
    "]\n",
    "# Load MNIST dataset as tensors\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oo1DfgFrLQDl"
   },
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0R8wc0UTLQDm"
   },
   "outputs": [],
   "source": [
    "# 4-Mark to complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWxFVJuQLQDm"
   },
   "outputs": [],
   "source": [
    "# Discriminator and Generator Loss function\n",
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return the loss of the discriminator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator model, which returns an image given z-dimensional noise\n",
    "        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function, which should be used to compare \n",
    "               the discriminator's predictions to the ground truth reality of the images \n",
    "               (e.g. fake = 0, real = 1)\n",
    "        real: a batch of real images\n",
    "        num_images: the number of images the generator should produce, \n",
    "                which is also the length of the real images\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    Returns:\n",
    "        disc_loss: a torch scalar loss value for the current batch\n",
    "    '''\n",
    "    #### START CODE HERE ####\n",
    "    \n",
    "    # Create noise vectors, use existing defined functions to create noise\n",
    "    fake_noise = \n",
    "    \n",
    "    # Generate batch (num_images) of fake images.\n",
    "    fake = \n",
    "    \n",
    "    # Discriminator prediction of generated fake images, ensure to use .detach() on generator results i.e. fake.detach() since generator is needed to calculate discriminator loss.\n",
    "    # This ensures that only the discriminator is updated\n",
    "    disc_fake_pred = \n",
    "    \n",
    "    # Calculate loss using criterion defined earlier\n",
    "    # ground truth for fake images are all zeros\n",
    "    disc_fake_loss = \n",
    "    \n",
    "    # Discriminator prediction of real images\n",
    "    disc_real_pred = \n",
    "    \n",
    "    # Calculate loss using criterion\n",
    "    # ground truth for real images are all ones\n",
    "    disc_real_loss = \n",
    "    \n",
    "    # Take avg of disc_fake_loss and disc_real_loss\n",
    "    disc_loss = \n",
    "    \n",
    "    # Write code for Return loss\n",
    "    return ?\n",
    "    #### END CODE HERE ####\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4z0eku6LQDm"
   },
   "outputs": [],
   "source": [
    "# 2-Mark to complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeGiY0D5LQDn"
   },
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return the loss of the generator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator model, which returns an image given z-dimensional noise\n",
    "        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function, which should be used to compare \n",
    "               the discriminator's predictions to the ground truth reality of the images \n",
    "               (e.g. fake = 0, real = 1)\n",
    "        num_images: the number of images the generator should produce, \n",
    "                which is also the length of the real images\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    Returns:\n",
    "        gen_loss: a torch scalar loss value for the current batch\n",
    "    '''\n",
    "\n",
    "    #### START CODE HERE ####\n",
    "    # Create noise vectors, use existing defined functions to create noise, ensure use of device argument\n",
    "    fake_noise = \n",
    "    \n",
    "    # Generate batch (num_images) of fake images.\n",
    "    fake = \n",
    "    \n",
    "    # Discriminator Prediction on generated fake images\n",
    "    disc_fake_pred = \n",
    "    \n",
    "    # Calculate generator loss using criterion\n",
    "    # For Ground truth remember that generator wants discriminator to think that fake images are real\n",
    "    gen_loss = \n",
    "\n",
    "    # Return generator loss\n",
    "    return ?\n",
    "\n",
    "    #### END CODE HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_u1T7ksbLQDn"
   },
   "outputs": [],
   "source": [
    "# Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOB4BULPLQDn"
   },
   "outputs": [],
   "source": [
    "# 2-Mark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlxZru5FLQDn"
   },
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "test_generator = True # Whether the generator should be tested\n",
    "gen_loss = False\n",
    "error = False\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
    "\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "\n",
    "        disc_opt.step()\n",
    "\n",
    "        if test_generator:\n",
    "            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n",
    "\n",
    "        #### START CODE HERE ####\n",
    "        \n",
    "        # Zero out the gradients \n",
    "        \n",
    "        # Calculate generator loss, use existing function defined for loss calculation\n",
    "        \n",
    "        # Backprop through the generator: update the gradients \n",
    "        \n",
    "        # update optimizer\n",
    "        \n",
    "        #### END CODE HERE ####\n",
    "\n",
    "        if test_generator: # For testing purposes, to check that your code changes the generator weights\n",
    "            try:\n",
    "                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n",
    "                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n",
    "            except:\n",
    "                error = True\n",
    "                print(\"Runtime tests have failed\")\n",
    "\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        if cur_step % display_step == 0 and cur_step > 0: ### Visualization code ###\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Question_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
